This module makes it easier to read and write data to SQL Server from Python using the Pandas Data Analysis Toolkit.

--------
Tutorial
--------

    1. Setting up your connections:

        The first thing you will need to do is set up a place to store your ODBC connections. If you are on a Linux machine all you need to do is:

            $ipython
            In [1]: import savvy_data as sd
            In [2]: sd.create_odbc_ini()

        This will create a (hidden) file in your home directory that can store all of your connections called odbc.ini. Once your odbc.ini file 
        is created you can then create individual SQL server connections called Data Source Names (DSNs). The process to do so is simple:

            In [3]: sd.add_dsn('savvy-uhc', 'devsql14', 'United_Health_Care')

        This command will store a DSN in your odbc.ini files that save the connection to the (ficticious) United_Health_Care database on devsql14.
        The first thing you input (in this example 'savvy-uhc') will be the name you use to call the database later, so make it easy to remember.
        You have now created your first connection! It is now possible to query databases, among other things coming up later. In case you forget
        what DSNs or Databases you are connected to you can see them both through simple commands:

            In [4]: savvy.get_dsn_list()
            Out[4]: ['savvy-uhc']

            In [5]: savvy.get_db_list()
            Out[5]: ['United_Health_Care']

        If you are on a Windows or OSX machine the process is slighty harder. In future this package *may* support non-Linux set-ups but for now
        you will have to create and check your DSNs manually. Both have GUIs that should make the process easier.
            
            See here for PC: http://blog.mclaughlinsoftware.com/2012/09/12/sql-server-odbc-osn/
            See here for OSX: http://www.actualtech.com/readme.php

    2. Querying the database:

        From this point forward the queries should work no matter what type of machine you are on, as long as you have set up your DSNs. The first
        thign you need to do is start a connection by calling the 'Sql' class. Following that all the commands are available. Querying is the main
        function of this module. To make a query call the 'query' function:

            In [6]: savvy = sd.Sql(dsn = 'savvy-uhc')
            In [7]: uhc_patient_stats = savvy.query('Select * From Patient_Stats')

        This query selected all variables from the Patient_Stats table of the United_Health_Care database (remember that database is saved in 
        savvy-uhc) and saved it into a Pandas DataFrame. DataFrames are the Python version of R dataframes and behave in much the same way. Thus
        the data should already be in a usable format (for more info see here: http://pandas.pydata.org/pandas-docs/dev/index.html). All queries
        are made exactly as they would be in SQL Server, but must be passed in a string (between quotes). It is much easier to pass complicated
        queries in a seperate variable:

            In [7]: query = "Select PatientID
                                ,PatientGender
                                ,PatientAge
                                ,PatientSteps
                                ,PatientRAF
                            From Patient_Stats"

            In [8]: uhc_patient_stats = savvy.query(query)

    3. Making changes to the database:

        After doing the analysis on your dataset you can write back into SQL, either into an already created database or by making your own:

            In [9]: table_query = 'Create Table My_Table (
                                        PatientID int,
                                        PatientGender bit,
                                        PatientAge int,
                                        PatientResult int
                                        );'

            In [10]: savvy.create_table(table_query)
            In [11]: savvy.insert('My_Table', 'My_Results')

        HINT: Don't forget to try using SQL as a back end for complex algorithms! Use the insert function to iteratively append data to a SQL
        table as your function is running. No more data loss on failure!

And that's it! There are a few other things you can do in this package put this will get you started. If you are interested in further functionality
read the documentation inside. This module should save you some time, especially when waiting on data support. Either enter the query your self or 
copy and paste it from a SQL script.

If you have any questions contact Ryan (RyanBrunt@savvysherpa.com) or Greg (GregRomrell@savvysherpa.com).
